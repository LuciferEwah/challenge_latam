{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DesafÃ­o Latam: AnÃ¡lisis y OptimizaciÃ³n de Memoria en Procesamiento de Datos\n",
    "\n",
    "## DescripciÃ³n del Proyecto\n",
    "\n",
    "El objetivo del proyecto es comparar diferentes librerÃ­as de procesamiento de datos en Python (`Modin`, `Polars`, `Dask`, `Ray`) para evaluar su rendimiento y uso de memoria al trabajar con un archivo JSONL que contiene datos de tweets.\n",
    "\n",
    "El proyecto abarca tres tipos de anÃ¡lisis principales:\n",
    "1. **Usuarios mÃ¡s mencionados en los tweets**.\n",
    "2. **Emojis mÃ¡s utilizados en los tweets**.\n",
    "3. **Fechas con mÃ¡s tweets y el usuario mÃ¡s activo por cada fecha**.\n",
    "\n",
    "## Herramientas Utilizadas\n",
    "\n",
    "### Modin\n",
    "`Modin` se eligiÃ³ por su capacidad para paralelizar y optimizar `pandas` utilizando `Ray` o `Dask` como backend distribuido, lo cual permite mejorar la eficiencia y reducir los tiempos de ejecuciÃ³n manteniendo la misma API de `pandas`.\n",
    "\n",
    "### Polars\n",
    "`Polars` es una librerÃ­a de procesamiento en memoria que ofrece paralelizaciÃ³n y un uso optimizado de la memoria, ideal para realizar operaciones de anÃ¡lisis en grandes volÃºmenes de datos. Se evaluÃ³ su rendimiento en comparaciÃ³n con `Modin` y `pandas`.\n",
    "\n",
    "### Dask y Ray\n",
    "Estas librerÃ­as se utilizaron como motores de ejecuciÃ³n distribuida para paralelizar las operaciones y simular un entorno distribuido. `Dask` y `Ray` permiten manejar tareas que requieren procesamiento paralelo y distribuyen la carga de trabajo entre mÃºltiples nÃºcleos de CPU o mÃ¡quinas.\n",
    "\n",
    "### Pandas\n",
    "`Pandas` se usÃ³ como base de comparaciÃ³n, ya que es la librerÃ­a mÃ¡s conocida para anÃ¡lisis de datos en Python. Se midiÃ³ su rendimiento para observar cÃ³mo se comporta en comparaciÃ³n con `Modin` y `Polars`.\n",
    "\n",
    "## Implementaciones\n",
    "\n",
    "Se implementaron las tres tareas de anÃ¡lisis con cada una de las herramientas mencionadas. El objetivo fue comparar el rendimiento de cada implementaciÃ³n en tÃ©rminos de:\n",
    "\n",
    "- **Tiempo de EjecuciÃ³n**: CuÃ¡nto tarda cada herramienta en completar el procesamiento de datos.\n",
    "- **Uso de Memoria**: CuÃ¡nta memoria utiliza cada implementaciÃ³n durante la ejecuciÃ³n.\n",
    "- **Escalabilidad**: CÃ³mo se comportan las herramientas al manejar grandes volÃºmenes de datos en un entorno distribuido o de mÃºltiples nÃºcleos.\n",
    "\n",
    "### 1. AnÃ¡lisis de Usuarios MÃ¡s Mencionados\n",
    "- Se identificaron los usuarios mÃ¡s mencionados en los tweets.\n",
    "- ComparaciÃ³n entre `Modin`, `Polars`, y `Pandas`.\n",
    "\n",
    "### 2. AnÃ¡lisis de Emojis MÃ¡s Utilizados\n",
    "- Se extrajeron y contaron los emojis presentes en los tweets.\n",
    "- ComparaciÃ³n de rendimiento entre `Modin`, `Polars`, y `Pandas`.\n",
    "\n",
    "### 3. AnÃ¡lisis de Fechas con MÃ¡s Tweets y Usuarios Activos\n",
    "- Se identificaron las fechas con mayor cantidad de tweets y se determinÃ³ el usuario mÃ¡s activo por cada fecha.\n",
    "- ComparaciÃ³n de tiempo y uso de memoria entre `Modin`, `Polars`, y `Pandas`.\n",
    "\n",
    "## Problemas con la ImplementaciÃ³n en la Nube\n",
    "\n",
    "Inicialmente, se tenÃ­a planeado probar algunas implementaciones en la nube para evaluar el rendimiento en un entorno distribuido. Sin embargo, debido a problemas para crear cuentas en servicios de nube, como la limitaciÃ³n de IP y problemas con el equipo utilizado, se optÃ³ por realizar las pruebas en un entorno local.\n",
    "\n",
    "A pesar de no contar con un entorno en la nube, `Ray` y `Dask` permitieron simular entornos distribuidos localmente, obteniendo buenos resultados.\n",
    "\n",
    "## Oportunidades de mejora\n",
    "\n",
    "- Se espera implementar el uso de `PySpark` en futuras versiones para evaluar su rendimiento en clÃºsteres de datos distribuidos.\n",
    "- Se recomienda realizar pruebas en un entorno de nube real para evaluar el rendimiento a gran escala.\n",
    "- Explorar otras herramientas de big data como `Apache Spark` o servicios de anÃ¡lisis en la nube como `BigQuery`.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "from q1_memory import q1_memory\n",
    "from q1_time import q1_time \n",
    "from q2_memory import q2_memory \n",
    "from q2_time import q2_time \n",
    "from q3_memory import q3_memory \n",
    "from q3_time import q3_time\n",
    "import ray  # Usar Ray como backend distribuido\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance_avg(file_path: str, func: callable, runs: int = 3) -> Tuple[float, float]:\n",
    "    \"\"\"Function to measure the average performance of the given function.\"\"\"\n",
    "    total_time = 0\n",
    "    max_memory = []\n",
    "\n",
    "    for _ in range(runs):\n",
    "        start_time = time.time()\n",
    "        mem_usage = memory_usage((func, (file_path,)), interval=0.1)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        total_time += (end_time - start_time)\n",
    "        max_memory.append(max(mem_usage))\n",
    "\n",
    "    avg_time = total_time / runs\n",
    "    avg_memory = sum(max_memory) / runs\n",
    "\n",
    "    return avg_time, avg_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo JSONL\n",
    "file_path = r\"C:\\Users\\Luci\\Documents\\GitHub\\challenge_latam\\src\\farmers-protest-tweets-2021-2-4.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 22:38:02,882\tINFO worker.py:1786 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JSONL file read successfully.\n",
      "âœ… JSONL file read successfully.\n",
      "âœ… JSONL file read successfully.\n",
      "âœ… Archivo JSONL leÃ­do exitosamente.\n",
      "âœ… Archivo JSONL leÃ­do exitosamente.\n",
      "âœ… Archivo JSONL leÃ­do exitosamente.\n",
      "Dask - Average time: 8.22 seconds, Average maximum memory usage: 264.47 MiB\n",
      "Polars - Average time: 1.41 seconds, Average maximum memory usage: 740.13 MiB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Measure performance for each method\n",
    "avg_time_q1_memory, avg_memory_q1_memory = measure_performance_avg(file_path, q1_memory)\n",
    "avg_time_q1_time, avg_memory_q1_time= measure_performance_avg(file_path, q1_time)\n",
    "\n",
    "# Print the results\n",
    "print(f\"modin - Average time: {avg_time_q1_memory:.2f} seconds, Average maximum memory usage: {avg_memory_q1_memory:.2f} MiB\")\n",
    "print(f\"polars - Average time: {avg_time_q1_time:.2f} seconds, Average maximum memory usage: {avg_memory_q1_time:.2f} MiB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JSONL file read successfully.\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n",
      "âœ… Archivo JSONL leÃ­do exitosamente.\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "print(q1_memory(file_path))\n",
    "print(q1_time(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JSONL file read successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `df.groupby(categorical_by, sort=False)` implementation has mismatches with pandas:\n",
      "the groupby keys will be sorted anyway, although the 'sort=False' was passed. See the following issue for more details: https://github.com/modin-project/modin/issues/3571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JSONL file read successfully.\n",
      "âœ… JSONL file read successfully.\n",
      "âœ… JSONL file read successfully.\n",
      "âœ… JSONL file read successfully.\n",
      "âœ… JSONL file read successfully.\n",
      "\n",
      " modin.pandas as mpd- Average time: 3.95 seconds, Average maximum memory usage: 426.49 MiB\n",
      "Dask - Average time: 7.87 seconds, Average maximum memory usage: 424.40 MiB\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Measure performance for each method\n",
    "avg_time_q2_memory, avg_memory_q2_memory = measure_performance_avg(file_path, q2_memory)\n",
    "avg_time_q2_time, avg_memory_q2_time= measure_performance_avg(file_path, q2_time)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\n modin.pandas as mpd- Average time: {avg_time_q2_memory:.2f} seconds, Average maximum memory usage: {avg_memory_q2_memory:.2f} MiB\")\n",
    "print(f\"modin.pandas - Average time: {avg_time_q2_time:.2f} seconds, Average maximum memory usage: {avg_memory_q2_time:.2f} MiB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JSONL file read successfully.\n",
      "[('ğŸ™', 2123), ('ğŸ˜‚', 633), ('ğŸŒ¾', 605), ('ğŸ’š', 533), ('ğŸ‘', 471), ('ğŸ‘‰', 450), ('ğŸ‡®ğŸ‡³', 426), ('ğŸ™ğŸ™', 403), ('ğŸ‘‡', 390), ('ğŸ½', 332)]\n",
      "âœ… JSONL file read successfully.\n",
      "[('ğŸ™', 2123), ('ğŸ˜‚', 633), ('ğŸŒ¾', 605), ('ğŸ’š', 533), ('ğŸ‘', 471), ('ğŸ‘‰', 450), ('ğŸ‡®ğŸ‡³', 426), ('ğŸ™ğŸ™', 403), ('ğŸ‘‡', 390), ('ğŸ½', 332)]\n"
     ]
    }
   ],
   "source": [
    "print(q2_memory(file_path))\n",
    "print(q2_time(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Archivo JSONL leÃ­do exitosamente.\n",
      "âœ… Archivo JSONL leÃ­do exitosamente.\n",
      "âœ… Archivo JSONL leÃ­do exitosamente.\n",
      "Q3 Time Optimized - Average time: 1.52 seconds, Average maximum memory usage: 865.43 MiB\n",
      "Q3 Time Optimized - Average time: 1.65 seconds, Average maximum memory usage: 497.21 MiB\n"
     ]
    }
   ],
   "source": [
    "# Measure performance for q3\n",
    "avg_time_q3_time, avg_memory_q3_time = measure_performance_avg(file_path, q3_time)\n",
    "\n",
    "# Measure performance for\n",
    "avg_time_q3_time_standard, avg_memory_q3_time_standard = measure_performance_avg(file_path, q3_memory)\n",
    "print(f\"orjson Time Optimized - Average time: {avg_time_q3_time:.2f} seconds, Average maximum memory usage: {avg_memory_q3_time:.2f} MiB\")\n",
    "print(f\"polars Time Optimized - Average time: {avg_time_q3_time_standard:.2f} seconds, Average maximum memory usage: {avg_memory_q3_time_standard:.2f} MiB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n",
      "âœ… Archivo JSONL leÃ­do exitosamente.\n",
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "print(q3_memory(file_path))\n",
    "print(q3_time(file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
