{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "from q1_memory import q1_memory\n",
    "from q1_time import q1_time \n",
    "from q2_memory import q2_memory \n",
    "from q2_time import q2_time \n",
    "import ray  # Usar Ray como backend distribuido\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance_avg(file_path: str, func: callable, runs: int = 3) -> Tuple[float, float]:\n",
    "    \"\"\"Function to measure the average performance of the given function.\"\"\"\n",
    "    total_time = 0\n",
    "    max_memory = []\n",
    "\n",
    "    for _ in range(runs):\n",
    "        start_time = time.time()\n",
    "        mem_usage = memory_usage((func, (file_path,)), interval=0.1)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        total_time += (end_time - start_time)\n",
    "        max_memory.append(max(mem_usage))\n",
    "\n",
    "    avg_time = total_time / runs\n",
    "    avg_memory = sum(max_memory) / runs\n",
    "\n",
    "    return avg_time, avg_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "file_path = r\"C:\\Users\\Luci\\Documents\\GitHub\\challenge_latam\\src\\farmers-protest-tweets-2021-2-4.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SyntaxWarning: invalid escape sequence '\\D'\n",
      "SyntaxWarning: invalid escape sequence '\\D'\n",
      "SyntaxWarning: invalid escape sequence '\\D'\n",
      "2024-09-27 02:37:20,063\tINFO worker.py:1786 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSONL file read successfully.\n",
      "✅ JSONL file read successfully.\n",
      "✅ JSONL file read successfully.\n",
      "✅ Archivo JSONL leído exitosamente.\n",
      "✅ Archivo JSONL leído exitosamente.\n",
      "✅ Archivo JSONL leído exitosamente.\n",
      "\\Dask - Average time: 6.90 seconds, Average maximum memory usage: 267.98 MiB\n",
      "Polars - Average time: 1.31 seconds, Average maximum memory usage: 722.04 MiB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Measure performance for each method\n",
    "avg_time_q1_memory, avg_memory_q1_memory = measure_performance_avg(file_path, q1_memory)\n",
    "avg_time_q1_time, avg_memory_q1_time= measure_performance_avg(file_path, q1_time)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\Dask - Average time: {avg_time_q1_memory:.2f} seconds, Average maximum memory usage: {avg_memory_q1_memory:.2f} MiB\")\n",
    "print(f\"Polars - Average time: {avg_time_q1_time:.2f} seconds, Average maximum memory usage: {avg_memory_q1_time:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSONL file read successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `df.groupby(categorical_by, sort=False)` implementation has mismatches with pandas:\n",
      "the groupby keys will be sorted anyway, although the 'sort=False' was passed. See the following issue for more details: https://github.com/modin-project/modin/issues/3571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSONL file read successfully.\n",
      "✅ JSONL file read successfully.\n",
      "✅ JSONL file read successfully.\n",
      "✅ JSONL file read successfully.\n",
      "✅ JSONL file read successfully.\n",
      "\n",
      " modin.pandas as mpd- Average time: 2.44 seconds, Average maximum memory usage: 398.80 MiB\n",
      "Dask - Average time: 5.94 seconds, Average maximum memory usage: 413.49 MiB\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Measure performance for each method\n",
    "avg_time_q2_memory, avg_memory_q2_memory = measure_performance_avg(file_path, q2_memory)\n",
    "avg_time_q2_time, avg_memory_q2_time= measure_performance_avg(file_path, q2_time)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\n modin.pandas as mpd- Average time: {avg_time_q2_memory:.2f} seconds, Average maximum memory usage: {avg_memory_q2_memory:.2f} MiB\")\n",
    "print(f\"Dask - Average time: {avg_time_q2_time:.2f} seconds, Average maximum memory usage: {avg_memory_q2_time:.2f} MiB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
